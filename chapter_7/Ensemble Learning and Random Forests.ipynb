{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320fb6c2",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Random Forests\n",
    "\n",
    "Suppose you ask 1000 person question, then aggregate their answers. In many cases you will find that this aggregated answer is better than an expertâ€™s answer. This what happen when you trying to aggregate different classifer and predict the same instance from these different classifer then take the majority vote.\n",
    "\n",
    "Suppose you have trained a few classifiers, each one achieving about 80% accuracy. You may have a Logistic Regression classifier, and SVM classifier, a Random Forest classifier, a K-Nearest Neighbors classifier, and perhaps a few more.\n",
    "\n",
    "<img src=\"2.png\">\n",
    "\n",
    "A very simple way to create an even better classifier is to aggregate the predictions of each classifier and predict the class that gets the most votes\n",
    "\n",
    "<img src=\"1.png\">\n",
    "\n",
    "You can use this **Ensemble** with the same model as weel as with different models but the best is to trying different models because the error will slightly different for model to the other one,  although of that same errors will be common for some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6952af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c485f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d0561b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f4229d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')\n",
    "voting_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6302815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.86\n",
      "RandomForestClassifier 1.0\n",
      "SVC 1.0\n",
      "VotingClassifier 1.0\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X)\n",
    "    print(clf.__class__.__name__, accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76fed5",
   "metadata": {},
   "source": [
    "# Note !\n",
    "\n",
    "If all classifiers are able to estimate class probabilities (i.e., they have a predict_proba()  method),  then  you  can  tell  Scikit-Learn  to  predict  the  class  with  the highest class probability, averaged over all the individual classifiers. This is called soft voting,   It  often  achieves  higher  performance  than  hard  voting  because  it  gives  more weight  to  highly  confident  votes.  All  you  need  to  do  is  replace  voting=\"hard\"  with voting=\"soft\"  and  ensure  that  all  classifiers  can  estimate  class  probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12be992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
