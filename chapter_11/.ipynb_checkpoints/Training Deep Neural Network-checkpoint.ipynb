{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835180d1",
   "metadata": {},
   "source": [
    "# Training Deep Neural Networks\n",
    "\n",
    "Last chapter we talked about neural network in genral, it was a shallow one where there are just few layers and maybe multiple nurons in these layers, beside of that we discuss the different keras API like sequential and functional model, talked about the tensorboard for visualization the difference runs, the callbacks to control the behavior of the models and fine tune the hyperparameters.\n",
    "\n",
    "In this chapter we will go deeper to train the deep neural network, which can help us doing complex tasks like classification hundred of objects not like what we have binary or 10-class problem, what about voice recognition and other complex problem. But with these problem to be solved there are different parts we should take care about like **Vanshing and Exploding Problems**, **Overfitting**, **Large NN with small data and vise Verse**, **Labeling the data and training time** all of these problem we will see how to handle to train deep NN.\n",
    "\n",
    "## Vanshing and Exploding Problems\n",
    "\n",
    "\"The backpropagation algorithm works by going from the output layer to the input layer, propagating the error gradient on the way, Unfortunately, gradients often get smaller and smaller as the algorithm progresses down to the lower layers. As a result, the Gradient Descent update leaves the lower layer connection weights virtually unchanged, and training never converges to a good solution. This is called the vanishing gradients problem. In some cases, the opposite can happen: the gradients can grow bigger and bigger, so many layers get insanely large weight updates and the algorithm diverges \", This is the exploding gradients proplem.\n",
    "\n",
    "One of the solution for these **Vanishing and Exploding Problems** is to combine some of the activation functions with some method of weights in lizards as in the table below.\n",
    "\n",
    "<img src=\"images/1.png\">\n",
    "\n",
    "By default, Keras uses Glorot initialization with a uniform distribution. You can change this to He initialization by setting kernel_initializer=\"he_uniform\" or kernel_initializer=\"he_normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbff09c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5837404",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f92b9",
   "metadata": {},
   "source": [
    "## He initialization instead of defaul Glorot initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e913b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.4191 - accuracy: 0.5981 - val_loss: 0.9511 - val_accuracy: 0.7122\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8333 - accuracy: 0.7411 - val_loss: 0.7321 - val_accuracy: 0.7704\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6975 - accuracy: 0.7747 - val_loss: 0.6474 - val_accuracy: 0.7900\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6320 - accuracy: 0.7937 - val_loss: 0.5966 - val_accuracy: 0.8066\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5902 - accuracy: 0.8046 - val_loss: 0.5634 - val_accuracy: 0.8164\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5610 - accuracy: 0.8124 - val_loss: 0.5384 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5387 - accuracy: 0.8187 - val_loss: 0.5228 - val_accuracy: 0.8246\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5210 - accuracy: 0.8242 - val_loss: 0.5052 - val_accuracy: 0.8324\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5067 - accuracy: 0.8281 - val_loss: 0.4967 - val_accuracy: 0.8358\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4947 - accuracy: 0.8312 - val_loss: 0.4823 - val_accuracy: 0.8398\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\",  kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\",  kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa8fca",
   "metadata": {},
   "source": [
    "###  He initialization with a uniform distribution, but based on fan_avg rather than fan_in as in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efc1737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.2572 - accuracy: 0.6165 - val_loss: 0.8611 - val_accuracy: 0.7222\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7797 - accuracy: 0.7437 - val_loss: 0.7018 - val_accuracy: 0.7762\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6714 - accuracy: 0.7810 - val_loss: 0.6267 - val_accuracy: 0.7988\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6116 - accuracy: 0.7994 - val_loss: 0.5796 - val_accuracy: 0.8126\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5720 - accuracy: 0.8104 - val_loss: 0.5478 - val_accuracy: 0.8228\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5433 - accuracy: 0.8186 - val_loss: 0.5267 - val_accuracy: 0.8286\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5217 - accuracy: 0.8239 - val_loss: 0.5071 - val_accuracy: 0.8320\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5046 - accuracy: 0.8294 - val_loss: 0.4919 - val_accuracy: 0.8364\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4904 - accuracy: 0.8335 - val_loss: 0.4804 - val_accuracy: 0.8400\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4791 - accuracy: 0.8359 - val_loss: 0.4696 - val_accuracy: 0.8440\n"
     ]
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg', distribution='uniform')\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\",  kernel_initializer=he_avg_init),\n",
    "    keras.layers.Dense(100, activation=\"relu\",  kernel_initializer=he_avg_init),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1262e5",
   "metadata": {},
   "source": [
    "## Nonsaturating Activation Functions\n",
    "\n",
    "Another slution of solving **Vanishing and Exploding Problems** is to use Non-saturated activation function, as usual we use **Sigmoid function** which saturated on when z is very large or very small, but there are another activation function have been appeared like Relu but it was lead to problem of **dying nurons** because of output 0 when z is less than 0, and to come over this problem the LeakyRelu and other variants of Relu have been introduced like Randomized Relu which introduce another hyper paramter to tune which is α, but this help us avoid the problem of dying nurons.\n",
    "\n",
    "Also, another activation function is outperform all of the Relu and its variance is  exponential linear unit (ELU), but it takes more time to train and test, but it converage in less number of epochs.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th><img src=\"images/2.png\"></th>\n",
    "<th><img src=\"images/3.png\"></th>\n",
    "\n",
    "</tr>\n",
    "</table>\n",
    "<th><img src=\"images/4.png\"></th>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289e4fef",
   "metadata": {},
   "source": [
    "## LeakyReLU instead of Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409d7666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.3303 - accuracy: 0.5848 - val_loss: 0.8938 - val_accuracy: 0.7060\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8048 - accuracy: 0.7343 - val_loss: 0.7195 - val_accuracy: 0.7630\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6872 - accuracy: 0.7744 - val_loss: 0.6369 - val_accuracy: 0.7872\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6257 - accuracy: 0.7939 - val_loss: 0.5922 - val_accuracy: 0.8042\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5857 - accuracy: 0.8064 - val_loss: 0.5585 - val_accuracy: 0.8158\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5568 - accuracy: 0.8136 - val_loss: 0.5335 - val_accuracy: 0.8250\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5351 - accuracy: 0.8207 - val_loss: 0.5145 - val_accuracy: 0.8298\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5181 - accuracy: 0.8259 - val_loss: 0.4988 - val_accuracy: 0.8356\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5036 - accuracy: 0.8306 - val_loss: 0.4920 - val_accuracy: 0.8326\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4924 - accuracy: 0.8332 - val_loss: 0.4772 - val_accuracy: 0.8428\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(alpha=.2),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(alpha=.2),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d1b6a",
   "metadata": {},
   "source": [
    "## Parametric Relu instead of Relu\n",
    "Now alpha we have used with .2 is learned by the model as model paramter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7472c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.2938 - accuracy: 0.6276 - val_loss: 0.8954 - val_accuracy: 0.7186\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8065 - accuracy: 0.7365 - val_loss: 0.7200 - val_accuracy: 0.7622\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6906 - accuracy: 0.7690 - val_loss: 0.6446 - val_accuracy: 0.7826\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6291 - accuracy: 0.7911 - val_loss: 0.5942 - val_accuracy: 0.8016\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5889 - accuracy: 0.8046 - val_loss: 0.5628 - val_accuracy: 0.8134\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5595 - accuracy: 0.8128 - val_loss: 0.5369 - val_accuracy: 0.8242\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5373 - accuracy: 0.8197 - val_loss: 0.5186 - val_accuracy: 0.8288\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5197 - accuracy: 0.8257 - val_loss: 0.5046 - val_accuracy: 0.8310\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5054 - accuracy: 0.8289 - val_loss: 0.4902 - val_accuracy: 0.8368\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4938 - accuracy: 0.8325 - val_loss: 0.4780 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273df06d",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "The previous solution for **Vanishing and Exploding Problems** can significantly reduce the vanishing and exploding gradients problems at the beginning of training, but it doesn’t guarantee that they won’t come back during training. So a new technique called Batch Normalization (BN) have been introduced to address the vanishing and exploding gradients problems.\n",
    "The technique consists of adding an operation in the model just before or after the activation function of each hidden layer.\n",
    "\n",
    "## BatchNormalization but after activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b1e1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10,  activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae7e0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s look at the parameters of the first BN layer. Two are trainable (by backprop), and two are not:\n",
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a871cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8745 - accuracy: 0.7056 - val_loss: 0.5874 - val_accuracy: 0.8038\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6043 - accuracy: 0.7915 - val_loss: 0.5053 - val_accuracy: 0.8266\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5437 - accuracy: 0.8104 - val_loss: 0.4707 - val_accuracy: 0.8382\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5112 - accuracy: 0.8208 - val_loss: 0.4486 - val_accuracy: 0.8426\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4918 - accuracy: 0.8261 - val_loss: 0.4344 - val_accuracy: 0.8478\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4739 - accuracy: 0.8352 - val_loss: 0.4214 - val_accuracy: 0.8496\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4634 - accuracy: 0.8379 - val_loss: 0.4112 - val_accuracy: 0.8548\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4494 - accuracy: 0.8431 - val_loss: 0.4034 - val_accuracy: 0.8578\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4421 - accuracy: 0.8445 - val_loss: 0.3972 - val_accuracy: 0.8610\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4325 - accuracy: 0.8475 - val_loss: 0.3909 - val_accuracy: 0.8644\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be564e1d",
   "metadata": {},
   "source": [
    "## BatchNormalization but before activation function\n",
    "\n",
    "**sometimes it give a better result than using it after activation function**\n",
    "\n",
    "- Also look at the result over 86 instead of 84 in other models without Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b5fa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.0902 - accuracy: 0.6584 - val_loss: 0.6968 - val_accuracy: 0.7810\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.7111 - accuracy: 0.7713 - val_loss: 0.5737 - val_accuracy: 0.8120\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.6178 - accuracy: 0.7955 - val_loss: 0.5140 - val_accuracy: 0.8280\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5675 - accuracy: 0.8096 - val_loss: 0.4787 - val_accuracy: 0.8382\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5362 - accuracy: 0.8179 - val_loss: 0.4533 - val_accuracy: 0.8456\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5131 - accuracy: 0.8247 - val_loss: 0.4366 - val_accuracy: 0.8512\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4953 - accuracy: 0.8299 - val_loss: 0.4243 - val_accuracy: 0.8548\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4764 - accuracy: 0.8345 - val_loss: 0.4132 - val_accuracy: 0.8610\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4670 - accuracy: 0.8374 - val_loss: 0.4033 - val_accuracy: 0.8636\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4548 - accuracy: 0.8419 - val_loss: 0.3949 - val_accuracy: 0.8646\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300,  kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8de3cb",
   "metadata": {},
   "source": [
    "## Lets do it with ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c64f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.9392 - accuracy: 0.6887 - val_loss: 0.6524 - val_accuracy: 0.7822\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6456 - accuracy: 0.7843 - val_loss: 0.5573 - val_accuracy: 0.8108\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5797 - accuracy: 0.8018 - val_loss: 0.5124 - val_accuracy: 0.8294\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5428 - accuracy: 0.8132 - val_loss: 0.4859 - val_accuracy: 0.8410\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5164 - accuracy: 0.8228 - val_loss: 0.4671 - val_accuracy: 0.8466\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5001 - accuracy: 0.8273 - val_loss: 0.4526 - val_accuracy: 0.8508\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4884 - accuracy: 0.8303 - val_loss: 0.4421 - val_accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4741 - accuracy: 0.8356 - val_loss: 0.4335 - val_accuracy: 0.8570\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4653 - accuracy: 0.8393 - val_loss: 0.4274 - val_accuracy: 0.8568\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4554 - accuracy: 0.8427 - val_loss: 0.4210 - val_accuracy: 0.8570\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300,  kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ELU(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ELU(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a0205",
   "metadata": {},
   "source": [
    "## BatchNormalization after activation function with ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d04d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.8618 - accuracy: 0.7054 - val_loss: 0.5645 - val_accuracy: 0.8056\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5814 - accuracy: 0.8004 - val_loss: 0.4947 - val_accuracy: 0.8312\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5264 - accuracy: 0.8176 - val_loss: 0.4626 - val_accuracy: 0.8436\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4985 - accuracy: 0.8257 - val_loss: 0.4445 - val_accuracy: 0.8502\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4794 - accuracy: 0.8324 - val_loss: 0.4304 - val_accuracy: 0.8554\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4639 - accuracy: 0.8381 - val_loss: 0.4203 - val_accuracy: 0.8602\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4524 - accuracy: 0.8415 - val_loss: 0.4116 - val_accuracy: 0.8616\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4412 - accuracy: 0.8451 - val_loss: 0.4048 - val_accuracy: 0.8628\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4344 - accuracy: 0.8476 - val_loss: 0.3990 - val_accuracy: 0.8674\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4255 - accuracy: 0.8503 - val_loss: 0.3929 - val_accuracy: 0.8670\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300,  kernel_initializer='he_normal'),\n",
    "    keras.layers.ELU(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.ELU(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd897851",
   "metadata": {},
   "source": [
    "## Change kernel_initializer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b99e2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7550 - accuracy: 0.7437 - val_loss: 0.5251 - val_accuracy: 0.8270\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5437 - accuracy: 0.8123 - val_loss: 0.4680 - val_accuracy: 0.8418\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4998 - accuracy: 0.8263 - val_loss: 0.4410 - val_accuracy: 0.8508\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4756 - accuracy: 0.8343 - val_loss: 0.4232 - val_accuracy: 0.8538\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4546 - accuracy: 0.8421 - val_loss: 0.4087 - val_accuracy: 0.8574\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4414 - accuracy: 0.8462 - val_loss: 0.4015 - val_accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4249 - accuracy: 0.8511 - val_loss: 0.3931 - val_accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4171 - accuracy: 0.8535 - val_loss: 0.3881 - val_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4110 - accuracy: 0.8568 - val_loss: 0.3829 - val_accuracy: 0.8662\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4018 - accuracy: 0.8595 - val_loss: 0.3762 - val_accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300,  kernel_initializer='lecun_normal'),\n",
    "    keras.layers.ELU(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, kernel_initializer='lecun_normal'),\n",
    "    keras.layers.ELU(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5948cd",
   "metadata": {},
   "source": [
    "# Reusing Pretrained Layers\n",
    "\n",
    "We have talked about the **Vanishing and Exploding Problems**, and different techniques to solve these problem from different weights initialization with different activation function, and lastely talked about the Batch Normalization.\n",
    "\n",
    "Now another problem is that maybe we do not have large training set, or we do not have the resource to build deep neural network from scratch, but there are some people who trained different architectures of Network on similar tasks and we can use their network with our new task which similar to the task they done. **This called Transfer Learning**.\n",
    "\n",
    "<img src=\"images/5.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "**The more similar the tasks are, the more layers you want to reuse (starting with the lower layers).**\n",
    "\n",
    "Try freezing all the reused layers first so gradient descent won’t modify them, then train the model and see the result. Then try unfreezing one or two of the top hidden layers to let backpropagation tweak them and see if performance improves and so on.\n",
    "\n",
    "The more training data you have, the more layers you can unfreeze. **It is also useful to reduce the learning rate when you unfreeze reused layers: this will avoid wrecking their fine-tuned weights**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4d4e0",
   "metadata": {},
   "source": [
    "## Transfer Learning With Keras\n",
    "\n",
    "We will try to train model on just 8 classes from the dataset, then use this trained model with the other two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6384de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    # ~ not operation that Inverts all the bits\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6] # All other classes\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    \n",
    "    return ((X[~y_5_or_6], y_A), (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34be057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43986, 28, 28)\n",
      "(200, 28, 28)\n",
      "[4 0 5 7 7 7 4 4 3 4 0 1 6 3 4 3 2 6 5 3 4 5 1 3 4 2 0 6 7 1]\n",
      "[1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_A.shape)\n",
    "print(X_train_B.shape)\n",
    "\n",
    "# from 0 to 7 because other classes are shifted down\n",
    "print(y_train_A[:30])\n",
    "\n",
    "# Contain only 0 or 1 1 if shirt and 0 if sandals\n",
    "print(y_train_B[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41153097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.5127 - accuracy: 0.8306 - val_loss: 0.3328 - val_accuracy: 0.8899\n",
      "Epoch 2/10\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.3499 - accuracy: 0.8812 - val_loss: 0.2947 - val_accuracy: 0.9043\n",
      "Epoch 3/10\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.3204 - accuracy: 0.8916 - val_loss: 0.2778 - val_accuracy: 0.9091\n",
      "Epoch 4/10\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.3035 - accuracy: 0.8973 - val_loss: 0.2683 - val_accuracy: 0.9113\n",
      "Epoch 5/10\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2897 - accuracy: 0.9032 - val_loss: 0.2590 - val_accuracy: 0.9131\n",
      "Epoch 6/10\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2811 - accuracy: 0.9056 - val_loss: 0.2530 - val_accuracy: 0.9153\n",
      "Epoch 7/10\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2761 - accuracy: 0.9077 - val_loss: 0.2507 - val_accuracy: 0.9160\n",
      "Epoch 8/10\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2669 - accuracy: 0.9092 - val_loss: 0.2457 - val_accuracy: 0.9158\n",
      "Epoch 9/10\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2640 - accuracy: 0.9117 - val_loss: 0.2424 - val_accuracy: 0.9158\n",
      "Epoch 10/10\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2582 - accuracy: 0.9122 - val_loss: 0.2400 - val_accuracy: 0.9193\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(8, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(1e-3),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train_A, y_train_A, epochs=10, validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2192a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_models/transfer_learning_8_class.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d9756",
   "metadata": {},
   "source": [
    "# Clone model\n",
    "First load the model, then clone it to be not affected by other model we transfer the model to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09d551bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model('trained_models/transfer_learning_8_class.h5')\n",
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61d82a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All layers except the output layer as we moved from 8 classes to 2 classes\n",
    "# Also the input shape for the two model is the same so there is no problem\n",
    "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
    "# As we classify image to either shirt or sandals\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b21a24",
   "metadata": {},
   "source": [
    "## Notes!\n",
    "\n",
    "Now we have used all the layers from model A we have trained with 8 classes, and as we mentioned in transfer learning, the new task we are dealing with is classifying image into either shirt or sandals, which is close to task we have trained.\n",
    "\n",
    "- The input is the same\n",
    "- It's image classification task\n",
    "- Just they different in the output from 8 classes to 2 classes so we do not use the output layer from model_A\n",
    "\n",
    "But as all layers of model_A are trained and we use these layers with model_B_on_A, but the output layer we have add to model_B_on_A is initialized with random weights, so its good to first **freeze the used layer** then let the model train for small number of epoch to get some good weights for  the output layer, and **unfreeze the used layer maybe just the top ones** and train again but with **small learning rate** to not change reused layer weights away, then again you can **unfreeze more layers and so on**, but each time you **freeze or unfreeze you need to compile again**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b85fb5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 1.2411 - accuracy: 0.3150 - val_loss: 0.9500 - val_accuracy: 0.4452\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7545 - accuracy: 0.5600 - val_loss: 0.6304 - val_accuracy: 0.6501\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4967 - accuracy: 0.7500 - val_loss: 0.4699 - val_accuracy: 0.7850\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3668 - accuracy: 0.8600 - val_loss: 0.3827 - val_accuracy: 0.8469\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2932 - accuracy: 0.9100 - val_loss: 0.3250 - val_accuracy: 0.8844\n"
     ]
    }
   ],
   "source": [
    "# Freeze all layer except output layer\n",
    "for layer in model_B_on_A.layers[:-1]: \n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model_B_on_A.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# X_train_B is the binary data \n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=5, validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1b3bcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 34ms/step - loss: 0.2581 - accuracy: 0.9100 - val_loss: 0.3137 - val_accuracy: 0.8905\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2464 - accuracy: 0.9150 - val_loss: 0.3046 - val_accuracy: 0.8945\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2257 - accuracy: 0.9400 - val_loss: 0.2960 - val_accuracy: 0.8976\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.2117 - accuracy: 0.9300 - val_loss: 0.2893 - val_accuracy: 0.9016\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2015 - accuracy: 0.9400 - val_loss: 0.2834 - val_accuracy: 0.9057\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2195 - accuracy: 0.9350 - val_loss: 0.2769 - val_accuracy: 0.9057\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2222 - accuracy: 0.9300 - val_loss: 0.2724 - val_accuracy: 0.9077\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2105 - accuracy: 0.9350 - val_loss: 0.2667 - val_accuracy: 0.9057\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1993 - accuracy: 0.9450 - val_loss: 0.2619 - val_accuracy: 0.9067\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2360 - accuracy: 0.9100 - val_loss: 0.2573 - val_accuracy: 0.9067\n"
     ]
    }
   ],
   "source": [
    "# unFreeze all layer except output layer\n",
    "for layer in model_B_on_A.layers[:-1]: \n",
    "    layer.trainable = True\n",
    "    \n",
    "# Compile the model again but with less learning rate\n",
    "model_B_on_A.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-4),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# X_train_B is the binary data \n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=10, validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85fc3e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 38ms/step - loss: 0.1873 - accuracy: 0.9550 - val_loss: 0.2548 - val_accuracy: 0.9087\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2044 - accuracy: 0.9550 - val_loss: 0.2526 - val_accuracy: 0.9097\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1833 - accuracy: 0.9450 - val_loss: 0.2502 - val_accuracy: 0.9097\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1807 - accuracy: 0.9650 - val_loss: 0.2480 - val_accuracy: 0.9138\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2294 - accuracy: 0.9450 - val_loss: 0.2455 - val_accuracy: 0.9138\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1957 - accuracy: 0.9350 - val_loss: 0.2432 - val_accuracy: 0.9158\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1729 - accuracy: 0.9650 - val_loss: 0.2410 - val_accuracy: 0.9158\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1751 - accuracy: 0.9550 - val_loss: 0.2389 - val_accuracy: 0.9189\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1882 - accuracy: 0.9600 - val_loss: 0.2371 - val_accuracy: 0.9189\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1856 - accuracy: 0.9600 - val_loss: 0.2350 - val_accuracy: 0.9199\n"
     ]
    }
   ],
   "source": [
    "# freeze some layer except output layer \n",
    "for layer in model_B_on_A.layers[:-2]: \n",
    "    layer.trainable = False\n",
    "    \n",
    "# Compile the model again\n",
    "model_B_on_A.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# fit again for another 10 epochs with some freeze for layers\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=10, validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6365615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 36ms/step - loss: 0.1651 - accuracy: 0.9550 - val_loss: 0.2317 - val_accuracy: 0.9209\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1791 - accuracy: 0.9600 - val_loss: 0.2275 - val_accuracy: 0.9189\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1521 - accuracy: 0.9700 - val_loss: 0.2251 - val_accuracy: 0.9178\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1617 - accuracy: 0.9650 - val_loss: 0.2216 - val_accuracy: 0.9239\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1723 - accuracy: 0.9500 - val_loss: 0.2188 - val_accuracy: 0.9260\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1549 - accuracy: 0.9700 - val_loss: 0.2161 - val_accuracy: 0.9260\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1565 - accuracy: 0.9700 - val_loss: 0.2137 - val_accuracy: 0.9260\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1546 - accuracy: 0.9600 - val_loss: 0.2116 - val_accuracy: 0.9280\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1452 - accuracy: 0.9700 - val_loss: 0.2097 - val_accuracy: 0.9300\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1613 - accuracy: 0.9600 - val_loss: 0.2083 - val_accuracy: 0.9320\n"
     ]
    }
   ],
   "source": [
    "# unfreeze all layers again\n",
    "for layer in model_B_on_A.layers[:-2]: \n",
    "    layer.trainable = True\n",
    "    \n",
    "# Compile the model again\n",
    "model_B_on_A.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-4),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# fit again for another 10 epochs with some freeze for layers\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=10, validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8802853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2011478692293167, 0.9330000281333923]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13d025a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5315 - accuracy: 0.8151 - val_loss: 0.4191 - val_accuracy: 0.8560\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4220 - accuracy: 0.8510 - val_loss: 0.3880 - val_accuracy: 0.8656\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3883 - accuracy: 0.8630 - val_loss: 0.3583 - val_accuracy: 0.8708\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3647 - accuracy: 0.8712 - val_loss: 0.3691 - val_accuracy: 0.8732\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3499 - accuracy: 0.8758 - val_loss: 0.3464 - val_accuracy: 0.8752\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3334 - accuracy: 0.8805 - val_loss: 0.3545 - val_accuracy: 0.8754\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3239 - accuracy: 0.8843 - val_loss: 0.3254 - val_accuracy: 0.8820\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3105 - accuracy: 0.8892 - val_loss: 0.3302 - val_accuracy: 0.8792\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3017 - accuracy: 0.8916 - val_loss: 0.3534 - val_accuracy: 0.8712\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2932 - accuracy: 0.8947 - val_loss: 0.3273 - val_accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=1e-3, momentum=.9),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21a55dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5215 - accuracy: 0.8176 - val_loss: 0.4008 - val_accuracy: 0.8618\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4164 - accuracy: 0.8530 - val_loss: 0.3958 - val_accuracy: 0.8612\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3853 - accuracy: 0.8625 - val_loss: 0.3724 - val_accuracy: 0.8674\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3639 - accuracy: 0.8707 - val_loss: 0.3531 - val_accuracy: 0.8764\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3458 - accuracy: 0.8773 - val_loss: 0.3481 - val_accuracy: 0.8748\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3321 - accuracy: 0.8799 - val_loss: 0.3316 - val_accuracy: 0.8808\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3204 - accuracy: 0.8852 - val_loss: 0.3392 - val_accuracy: 0.8814\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3078 - accuracy: 0.8893 - val_loss: 0.3184 - val_accuracy: 0.8872\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3003 - accuracy: 0.8930 - val_loss: 0.3221 - val_accuracy: 0.8834\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2933 - accuracy: 0.8943 - val_loss: 0.3122 - val_accuracy: 0.8902\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=1e-3, momentum=.9,\n",
    "                                     nesterov=True), metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6051eecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4718 - accuracy: 0.8292 - val_loss: 0.4020 - val_accuracy: 0.8526\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3617 - accuracy: 0.8672 - val_loss: 0.3387 - val_accuracy: 0.8764\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3258 - accuracy: 0.8805 - val_loss: 0.3504 - val_accuracy: 0.8724\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2989 - accuracy: 0.8917 - val_loss: 0.3615 - val_accuracy: 0.8722\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2817 - accuracy: 0.8968 - val_loss: 0.3220 - val_accuracy: 0.8868\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2678 - accuracy: 0.9019 - val_loss: 0.3158 - val_accuracy: 0.8880\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2551 - accuracy: 0.9063 - val_loss: 0.3032 - val_accuracy: 0.8950\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2442 - accuracy: 0.9116 - val_loss: 0.3149 - val_accuracy: 0.8854\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2346 - accuracy: 0.9132 - val_loss: 0.3161 - val_accuracy: 0.8922\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2268 - accuracy: 0.9159 - val_loss: 0.3365 - val_accuracy: 0.8852\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=1e-3, rho=.9),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33a7cb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4745 - accuracy: 0.8292 - val_loss: 0.4025 - val_accuracy: 0.8536\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3667 - accuracy: 0.8660 - val_loss: 0.4270 - val_accuracy: 0.8434\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3315 - accuracy: 0.8779 - val_loss: 0.3235 - val_accuracy: 0.8860\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3034 - accuracy: 0.8888 - val_loss: 0.3212 - val_accuracy: 0.8870\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2844 - accuracy: 0.8929 - val_loss: 0.3196 - val_accuracy: 0.8880\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2661 - accuracy: 0.9014 - val_loss: 0.3509 - val_accuracy: 0.8704\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2535 - accuracy: 0.9053 - val_loss: 0.3203 - val_accuracy: 0.8876\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2383 - accuracy: 0.9113 - val_loss: 0.3379 - val_accuracy: 0.8786\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2278 - accuracy: 0.9141 - val_loss: 0.3293 - val_accuracy: 0.8830\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2173 - accuracy: 0.9181 - val_loss: 0.3113 - val_accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=1e-3,\n",
    "                                                                 beta_1=.9, beta_2=.999), metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6ac470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5306 - accuracy: 0.8156 - val_loss: 0.4244 - val_accuracy: 0.8512\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4248 - accuracy: 0.8479 - val_loss: 0.3895 - val_accuracy: 0.8650\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3931 - accuracy: 0.8610 - val_loss: 0.3760 - val_accuracy: 0.8674\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3748 - accuracy: 0.8674 - val_loss: 0.3622 - val_accuracy: 0.8728\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3595 - accuracy: 0.8721 - val_loss: 0.3539 - val_accuracy: 0.8742\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3480 - accuracy: 0.8767 - val_loss: 0.3580 - val_accuracy: 0.8756\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3370 - accuracy: 0.8806 - val_loss: 0.3586 - val_accuracy: 0.8694\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3289 - accuracy: 0.8825 - val_loss: 0.3419 - val_accuracy: 0.8796\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3218 - accuracy: 0.8854 - val_loss: 0.3370 - val_accuracy: 0.8782\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3154 - accuracy: 0.8872 - val_loss: 0.3257 - val_accuracy: 0.8846\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-2, decay=1e-4),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b1afb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5186 - accuracy: 0.8131 - val_loss: 0.4566 - val_accuracy: 0.8356\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4153 - accuracy: 0.8493 - val_loss: 0.4003 - val_accuracy: 0.8540\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3768 - accuracy: 0.8626 - val_loss: 0.3864 - val_accuracy: 0.8646\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3468 - accuracy: 0.8731 - val_loss: 0.3582 - val_accuracy: 0.8724\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3213 - accuracy: 0.8815 - val_loss: 0.3617 - val_accuracy: 0.8714\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3060 - accuracy: 0.8864 - val_loss: 0.3463 - val_accuracy: 0.8764\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2858 - accuracy: 0.8931 - val_loss: 0.3239 - val_accuracy: 0.8824\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2691 - accuracy: 0.8996 - val_loss: 0.3817 - val_accuracy: 0.8678\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2606 - accuracy: 0.9036 - val_loss: 0.3264 - val_accuracy: 0.8840\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2444 - accuracy: 0.9095 - val_loss: 0.3122 - val_accuracy: 0.8882\n"
     ]
    }
   ],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * .1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=.01, s=20)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(beta_1=.9, beta_2=.999), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49b27b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5210 - accuracy: 0.8137 - val_loss: 0.4529 - val_accuracy: 0.8332\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4199 - accuracy: 0.8471 - val_loss: 0.3866 - val_accuracy: 0.8610\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3906 - accuracy: 0.8568 - val_loss: 0.3625 - val_accuracy: 0.8694\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3630 - accuracy: 0.8645 - val_loss: 0.4027 - val_accuracy: 0.8616\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3475 - accuracy: 0.8713 - val_loss: 0.3378 - val_accuracy: 0.8792\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2991 - accuracy: 0.8897 - val_loss: 0.3151 - val_accuracy: 0.8904\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2884 - accuracy: 0.8930 - val_loss: 0.3331 - val_accuracy: 0.8784\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2767 - accuracy: 0.8971 - val_loss: 0.3401 - val_accuracy: 0.8782\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2704 - accuracy: 0.8989 - val_loss: 0.3320 - val_accuracy: 0.8852\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2615 - accuracy: 0.9012 - val_loss: 0.3363 - val_accuracy: 0.8816\n"
     ]
    }
   ],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return .01\n",
    "    elif epoch < 15:\n",
    "        return .005\n",
    "    else:\n",
    "        return .001\n",
    "\n",
    "    \n",
    "    \n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(beta_1=.9, beta_2=.999), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83a188b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4751 - accuracy: 0.8303 - val_loss: 0.4016 - val_accuracy: 0.8508\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3669 - accuracy: 0.8655 - val_loss: 0.3891 - val_accuracy: 0.8648\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3307 - accuracy: 0.8783 - val_loss: 0.3106 - val_accuracy: 0.8878\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3025 - accuracy: 0.8867 - val_loss: 0.3408 - val_accuracy: 0.8782\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2839 - accuracy: 0.8941 - val_loss: 0.3141 - val_accuracy: 0.8856\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2668 - accuracy: 0.9007 - val_loss: 0.3425 - val_accuracy: 0.8768\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2507 - accuracy: 0.9062 - val_loss: 0.2899 - val_accuracy: 0.8952\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2402 - accuracy: 0.9098 - val_loss: 0.3211 - val_accuracy: 0.8796\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2287 - accuracy: 0.9137 - val_loss: 0.2962 - val_accuracy: 0.8906\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2152 - accuracy: 0.9177 - val_loss: 0.3549 - val_accuracy: 0.8842\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2082 - accuracy: 0.9215 - val_loss: 0.3014 - val_accuracy: 0.8914\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1999 - accuracy: 0.9236 - val_loss: 0.3179 - val_accuracy: 0.8836\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1664 - accuracy: 0.9370 - val_loss: 0.2921 - val_accuracy: 0.8962\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1549 - accuracy: 0.9407 - val_loss: 0.3076 - val_accuracy: 0.8992\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1478 - accuracy: 0.9433 - val_loss: 0.2833 - val_accuracy: 0.9040\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1421 - accuracy: 0.9465 - val_loss: 0.3287 - val_accuracy: 0.8898\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1349 - accuracy: 0.9490 - val_loss: 0.3203 - val_accuracy: 0.9022\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1291 - accuracy: 0.9509 - val_loss: 0.3268 - val_accuracy: 0.8932\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1260 - accuracy: 0.9518 - val_loss: 0.3376 - val_accuracy: 0.8962\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1220 - accuracy: 0.9541 - val_loss: 0.3431 - val_accuracy: 0.8944\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=.5, patience=5)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(beta_1=.9, beta_2=.999), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d390e4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.4176 - accuracy: 0.7038 - val_loss: 1.9205 - val_accuracy: 0.4756\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.9414 - accuracy: 0.7519 - val_loss: 1.1757 - val_accuracy: 0.6632\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.9179 - accuracy: 0.7670 - val_loss: 0.9820 - val_accuracy: 0.7480\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.8557 - accuracy: 0.7753 - val_loss: 0.9199 - val_accuracy: 0.7324\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.8112 - accuracy: 0.7802 - val_loss: 0.8625 - val_accuracy: 0.7752\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.7954 - accuracy: 0.7868 - val_loss: 0.9766 - val_accuracy: 0.7332\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.7670 - accuracy: 0.7919 - val_loss: 0.7834 - val_accuracy: 0.7776\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.7360 - accuracy: 0.7928 - val_loss: 0.8200 - val_accuracy: 0.7652\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.7156 - accuracy: 0.7973 - val_loss: 0.8064 - val_accuracy: 0.7612\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.6907 - accuracy: 0.8018 - val_loss: 0.7662 - val_accuracy: 0.7802\n"
     ]
    }
   ],
   "source": [
    "exponential_decay_fn = exponential_decay(lr0=.01, s=20)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation='elu', kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=keras.regularizers.l2(.01))\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(100),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(10, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(beta_1=.9, beta_2=.999), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebee9318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 6.5325 - accuracy: 0.6712 - val_loss: 5.1332 - val_accuracy: 0.6788\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.5529 - accuracy: 0.7028 - val_loss: 4.4765 - val_accuracy: 0.7202\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.1590 - accuracy: 0.7121 - val_loss: 4.4665 - val_accuracy: 0.5820\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.8190 - accuracy: 0.7187 - val_loss: 3.7893 - val_accuracy: 0.6750\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5012 - accuracy: 0.7225 - val_loss: 3.4912 - val_accuracy: 0.7388\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.2389 - accuracy: 0.7259 - val_loss: 3.3381 - val_accuracy: 0.6878\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.0283 - accuracy: 0.7309 - val_loss: 2.9650 - val_accuracy: 0.7010\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 2.7756 - accuracy: 0.7384 - val_loss: 3.0330 - val_accuracy: 0.6758\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 2.5603 - accuracy: 0.7430 - val_loss: 2.8685 - val_accuracy: 0.6490\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 2.3803 - accuracy: 0.7472 - val_loss: 2.4087 - val_accuracy: 0.6948\n"
     ]
    }
   ],
   "source": [
    "exponential_decay_fn = exponential_decay(lr0=.01, s=20)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation='elu', kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=keras.regularizers.l1_l2(.01))\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(100),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(10, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(beta_1=.9, beta_2=.999), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64ce364e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.0111 - accuracy: 0.6754 - val_loss: 1.2051 - val_accuracy: 0.7238\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 1.0891 - accuracy: 0.7375 - val_loss: 0.9478 - val_accuracy: 0.7794\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.9674 - accuracy: 0.7516 - val_loss: 0.9121 - val_accuracy: 0.7746\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.9188 - accuracy: 0.7581 - val_loss: 1.0972 - val_accuracy: 0.7120\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8736 - accuracy: 0.7645 - val_loss: 0.9104 - val_accuracy: 0.7566\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8252 - accuracy: 0.7715 - val_loss: 0.7692 - val_accuracy: 0.8122\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.8019 - accuracy: 0.7731 - val_loss: 0.7513 - val_accuracy: 0.7920\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.7824 - accuracy: 0.7766 - val_loss: 0.7565 - val_accuracy: 0.7968\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.7523 - accuracy: 0.7808 - val_loss: 0.7012 - val_accuracy: 0.7958\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7379 - accuracy: 0.7823 - val_loss: 0.6677 - val_accuracy: 0.8090\n"
     ]
    }
   ],
   "source": [
    "exponential_decay_fn = exponential_decay(lr0=.01, s=20)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation='elu', kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=keras.regularizers.l2(.05))\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(300),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(100),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(10, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(beta_1=.9, beta_2=.999), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b97a217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5728 - accuracy: 0.7918 - val_loss: 0.4370 - val_accuracy: 0.8358\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4838 - accuracy: 0.8229 - val_loss: 0.3795 - val_accuracy: 0.8516\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4457 - accuracy: 0.8359 - val_loss: 0.3755 - val_accuracy: 0.8568\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4238 - accuracy: 0.8453 - val_loss: 0.3462 - val_accuracy: 0.8720\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4049 - accuracy: 0.8508 - val_loss: 0.3197 - val_accuracy: 0.8802\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3875 - accuracy: 0.8571 - val_loss: 0.3214 - val_accuracy: 0.8808\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3752 - accuracy: 0.8618 - val_loss: 0.3040 - val_accuracy: 0.8846\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3616 - accuracy: 0.8664 - val_loss: 0.3021 - val_accuracy: 0.8866\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3537 - accuracy: 0.8680 - val_loss: 0.2921 - val_accuracy: 0.8900\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3472 - accuracy: 0.8719 - val_loss: 0.2884 - val_accuracy: 0.8956\n"
     ]
    }
   ],
   "source": [
    "exponential_decay_fn = exponential_decay(lr0=.01, s=20)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation='elu', kernel_initializer='he_normal')\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=.2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(300),\n",
    "    keras.layers.Dropout(rate=.2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(100),\n",
    "    keras.layers.Dropout(rate=.2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(10, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(beta_1=.9, beta_2=.999), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c846749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5645 - accuracy: 0.7979 - val_loss: 0.4224 - val_accuracy: 0.8476\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4586 - accuracy: 0.8335 - val_loss: 0.3744 - val_accuracy: 0.8612\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4252 - accuracy: 0.8446 - val_loss: 0.3628 - val_accuracy: 0.8588\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3983 - accuracy: 0.8539 - val_loss: 0.3210 - val_accuracy: 0.8794\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3790 - accuracy: 0.8594 - val_loss: 0.3110 - val_accuracy: 0.8834\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3630 - accuracy: 0.8688 - val_loss: 0.3008 - val_accuracy: 0.8880\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3484 - accuracy: 0.8706 - val_loss: 0.2924 - val_accuracy: 0.8884\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3362 - accuracy: 0.8756 - val_loss: 0.2848 - val_accuracy: 0.8932\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3272 - accuracy: 0.8797 - val_loss: 0.2953 - val_accuracy: 0.8864\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3165 - accuracy: 0.8822 - val_loss: 0.2862 - val_accuracy: 0.8894\n"
     ]
    }
   ],
   "source": [
    "exponential_decay_fn = exponential_decay(lr0=.01, s=20)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation='elu', kernel_initializer='he_normal')\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=.2),\n",
    "    RegularizedDense(300),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=.2),\n",
    "    RegularizedDense(100),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=.2),\n",
    "    RegularizedDense(10, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(beta_1=.9, beta_2=.999), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8786311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3157 - accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3157493472099304, 0.883400022983551]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a530175c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5260 - accuracy: 0.8116 - val_loss: 0.3712 - val_accuracy: 0.8654\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4125 - accuracy: 0.8497 - val_loss: 0.3861 - val_accuracy: 0.8556\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3748 - accuracy: 0.8645 - val_loss: 0.3190 - val_accuracy: 0.8834\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3401 - accuracy: 0.8751 - val_loss: 0.3288 - val_accuracy: 0.8796\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3214 - accuracy: 0.8822 - val_loss: 0.3513 - val_accuracy: 0.8746\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2985 - accuracy: 0.8894 - val_loss: 0.3332 - val_accuracy: 0.8812\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2815 - accuracy: 0.8948 - val_loss: 0.3460 - val_accuracy: 0.8810\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2681 - accuracy: 0.8999 - val_loss: 0.2910 - val_accuracy: 0.8946\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2512 - accuracy: 0.9053 - val_loss: 0.3010 - val_accuracy: 0.8896\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2388 - accuracy: 0.9102 - val_loss: 0.2998 - val_accuracy: 0.8948\n"
     ]
    }
   ],
   "source": [
    "exponential_decay_fn = exponential_decay(lr0=.01, s=20)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation='elu', kernel_initializer='he_normal')\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(300),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    RegularizedDense(100),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=.2),\n",
    "    RegularizedDense(10, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(beta_1=.9, beta_2=.999), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6143edcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3216792941093445, 0.8920000195503235]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40eaffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
