{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting Numbers MNIST Dataset\n",
    "\n",
    "Let's take a look at a scenario where we can recognize different numbers [0-9].\n",
    "\n",
    "**The data set are about 70,000 image 60,000 of them as training and 10,000 as testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = f\"{os.getcwd()}/csv_files/mnist.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path=file_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data set is two sets each of them are two lists of training and labeling data of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Training data are:  (60000, 28, 28)\n",
      "Our Testing data are:  (10000, 28, 28)\n",
      "Our labels of Training data are:  (60000,)\n",
      "Our labels of Testing data are:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Our Training data are: \", X_train.shape)\n",
    "print(\"Our Testing data are: \", X_test.shape)\n",
    "print(\"Our labels of Training data are: \", y_train.shape)\n",
    "print(\"Our labels of Testing data are: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize an image of your data with its features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features of the image 5 are\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1  13  88 156\n",
      "  254 162  89   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  61 145 145 145 151 253 253 253\n",
      "  253 253 217  21   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  25  66 157 235 253 253 253 254 253 248 217\n",
      "  243 253 253  36   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 106 226 253 253 253 253 253 149 142  84  72  10\n",
      "  195 253 196  12   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 128 253 253 207 193 146  72   4   0   0   0  49\n",
      "  253 253 139   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   9  60  60  14   0   0   0   0   0   0   0  84\n",
      "  253 232  34   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      "  253  83   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 135 242\n",
      "  230  37   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  11 199 232\n",
      "   52   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  12 243 253 147\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  19 254 212   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  12 203 251  87   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 138 254 212   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  45 244 246  36   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 230 253 155   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 110 248 160  29   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  70 247 253  92   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 189 253 114   2   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 206 253  24   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 206 253  24   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "The label of the image 5 are:  7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0171466ed0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The features of the image 5 are\\n\",X_train[103])\n",
    "print(\"The label of the image 5 are: \",y_train[103])\n",
    "plt.imshow(X_train[103])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features normalization\n",
    "\n",
    "As we saw the values of each pixel in the image is between 0 and 255 which our scale of brightness.\n",
    "but it's always useful for our model to learn within specific range of values and its help a lot for computational operations that happen in the Neural Network, and helpful for systems doing Math operations fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test  = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    '''\n",
    "    it's useful to use call back function that terminate your algorithm when its reach the accuracy you need.\n",
    "    it's save a lot of time.\n",
    "    '''\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') > 0.99):\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNmodel(X,Y, epochs):\n",
    "    '''\n",
    "    A Neural Network that contain just 4 layers.\n",
    "    input layer instead of each image as 28*28 this will Flatten() to be 784.\n",
    "    first hidden layer with 512 neurons and use relu as activation function.\n",
    "    second hidden layer with 256 neurons and use relu as activation function.\n",
    "    output layer with 10 predicted values in our data.\n",
    "    '''\n",
    "\n",
    "    callbacks = myCallback() # instance from the class\n",
    "    model = tf.keras.Sequential() # create sequential model\n",
    "    model.add(tf.keras.layers.Flatten()) # input layer\n",
    "    model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu)) # first hidden layer\n",
    "    model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu)) # second hidden layer\n",
    "    model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax)) # output layer\n",
    "\n",
    "# compile the model with Adam optimizer Algorithm\n",
    "    model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X,Y, epochs=epochs, callbacks=[callbacks])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.1831 - accuracy: 0.9440\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.0781 - accuracy: 0.9750\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.0549 - accuracy: 0.9829\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0441 - accuracy: 0.9861\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 11s 175us/sample - loss: 0.0353 - accuracy: 0.9892\n",
      "Epoch 6/15\n",
      "59680/60000 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9907\n",
      "Reached 99% accuracy so cancelling training!\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.0289 - accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "model = NNmodel(X_train, y_train, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 83us/sample - loss: 0.0890 - accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0889796699856457, 0.9771]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test the model with unseen data\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.6259155e-19, 1.0000000e+00, 1.6906992e-16, 2.5091027e-16,\n",
       "       2.6250364e-09, 1.6728524e-15, 8.4123921e-18, 4.8010695e-10,\n",
       "       2.2627188e-10, 4.7787182e-12], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(predict[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0130555090>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
