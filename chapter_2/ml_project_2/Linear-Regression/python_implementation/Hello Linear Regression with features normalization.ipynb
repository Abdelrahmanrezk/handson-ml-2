{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abdelrahman Rezk\n",
    "# ML & NLP Student\n",
    "\n",
    "# Web Developer \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Linear regression example that explain at basic level how the model work with simple data that will create every thing from 0 level and steps of work will be on these function\n",
    "h(x) predicted value\n",
    "cost function\n",
    "gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [5, 20, 6],\n",
    "    [5, 35 ,6],\n",
    "    [6, 38, 8],\n",
    "    [7, 40, 8],\n",
    "    [7, 46, 10]\n",
    "])\n",
    "print(\"###########################################\")\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([\n",
    "    [114],\n",
    "    [120],\n",
    "    [123],\n",
    "    [121],\n",
    "    [135]\n",
    "    \n",
    "])\n",
    "print(\"###########################################\")\n",
    "\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "assume that values at beginning\n",
    "there are a four theta for 4 features\n",
    "includeing x0 that is what will extend X features for \n",
    "to be 5*4 instead of 5*3 and x0=1 for each training example\n",
    "'''\n",
    "\n",
    "thetas = np.array([\n",
    "    [5],\n",
    "    [2],\n",
    "    [3],\n",
    "    [6]\n",
    "])\n",
    "print(\"###########################################\")\n",
    "print(thetas.shape)\n",
    "thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend X features to be 5*4 instead of 5*3 and x0=1\n",
    "\n",
    "X = np.column_stack([np.ones((X.shape[0],1), dtype=int), X])\n",
    "print(\"###########################################\")\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "'''\n",
    "   Features Normalization\n",
    "'''\n",
    "X = (X - np.mean(X))/ np.std(X)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function\n",
    "    implemented using vectorized version\n",
    "Now we should calculate the cost function that help us knowing what the cost error we have from prediction values and actual values.\n",
    "\n",
    "\n",
    "<font color='red'> J(thetas) = 1/(2*m) * transpose((X*thetas - y)) * (X*thetas - y) </font>\n",
    "\n",
    "<font color='red'> h(x) = thetas*X </font>\n",
    "\n",
    "sometime we will handle that to be theta transpose and X because of will vectorize everything without loops\n",
    "\n",
    "You can take this code to evaluate math behind and you will see same result\n",
    "\n",
    "actually X = 5*4 & thetas 4*1 so we can multiply and get the same as if \n",
    "\n",
    "we transpose theta and x to be thetas.T * X.T thats because of math behind matrix\n",
    "    \n",
    "    h_x = np.dot(x, theats)\n",
    "    h_x2 = np.dot(thetas.T, x.T)\n",
    "    print(h_x.shape)\n",
    "    print(h_x2.shape)\n",
    "    print(h_x)\n",
    "    print(h_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costfunction(x, theats, y,m):\n",
    "    '''\n",
    "        this function will return the cost function as we explain above\n",
    "        arguments\n",
    "            x is the features of our training examples\n",
    "            this that what we need to get at the end \n",
    "            which minimize your cost function with new examples            \n",
    "            y is the actual value for each training example\n",
    "            m the number of our training examples\n",
    "        returned value\n",
    "            the cost for the all training examples in J\n",
    "    '''\n",
    "    '''\n",
    "    unvectorize version\n",
    "    J(thetas) = 1/(2*m) * sum(h(x)-y).^2\n",
    "        let us implement each step for understanding\n",
    "        h_x = np.dot(x, theats)\n",
    "        below we get the difference between actual and predicted values\n",
    "        predicted_actual = (h_x-y) * (h_x-y)\n",
    "        cost_error = np.sum(predicted - actual)\n",
    "    '''\n",
    "\n",
    "    J = 0\n",
    "    J = (1/(2*m)) * np.dot(np.transpose((np.dot(x,thetas) - y)), (np.dot(x,thetas) - y))\n",
    "    print(\"#############################################\")\n",
    "#     print(\"Actual values are \\n\",y)\n",
    "#     print(\"Multiply thetas by features x \\n\",h_x)\n",
    "#     print(\"difference between each training example we predict and actual value y \\n\",predicted_actual)\n",
    "#     print(\"summation all of the difference in cost_error \\n\",cost_error)\n",
    "    print(\"divide cost_erro by 2*m \\n\",J)\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = costfunction(X,thetas,y,X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent \n",
    "Now we should calculate thetas and reassigned it \n",
    "for new values with each iteration of gradient descent \n",
    "because we need the values of theta that minimize our cost function\n",
    "we calculate above with each step of gradient decent we will calculate cost function to check if its actually minimized or not\n",
    "\n",
    "vectorized version \n",
    "\n",
    "<font color='red'> thetas = thetas -( alpha * (1/m)) * transpose(X)*(X*thetas-y) </font>\n",
    "\n",
    "<font color='red'> h(x) = thetas*X </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientdescent(x,thetas,y,m,alpha):\n",
    "#     predicted_actual = np.power(h_x-y,2)\n",
    "#     mutiply_by_x = predicted_actual * x # here is a element wise multiplication\n",
    "    '''\n",
    "        we use vectorize version \n",
    "    '''\n",
    "    '''\n",
    "        unvectorized version\n",
    "        thetas = thetas -( alpha * (1/m)) * sumation(((h(x) - y))*x)\n",
    "    '''\n",
    "    thetas = thetas - (alpha/m) * np.dot(X.T, (np.dot(x, thetas)-y))\n",
    "    \n",
    "    return thetas\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = gradientdescent(X,thetas,y,X.shape[0],.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    '''\n",
    "        we use vectorize version \n",
    "    '''\n",
    "    thetas = gradientdescent(X, thetas, y, X.shape[0], .2)\n",
    "    costs = costfunction(X,thetas,y,X.shape[0])\n",
    "    print(\"###########################################\")\n",
    "    print(\"grad after\\n\", thetas)\n",
    "    print(\"cost after\\n\",costs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([\n",
    "    [1, 3, 22,  8],\n",
    "    [1, 5, 20,  6],\n",
    "])\n",
    "test = (test - np.mean(test))/ np.std(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.dot(thetas.T, test.T)\n",
    "print((d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without features normaliztion its required about 100000 &\n",
    "#  alot of debugging to arrive at same result  ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
